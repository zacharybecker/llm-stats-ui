services:
  model-stats-ui:
    build: .
    ports:
      - "3001:3001"
    volumes:
      - ./config.yaml:/app/config/config.yaml:ro
    environment:
      - NODE_ENV=production
      - PORT=3001
      - CONFIG_PATH=/app/config/config.yaml
      - APP_NAME=Model Stats
      # Cache TTLs (in seconds)
      - CACHE_TTL=300
      - OPENROUTER_CACHE_TTL=300
      - LITELLM_PRICING_CACHE_TTL=1800
      - BENCHMARK_CACHE_TTL=3600
      - ARENA_CACHE_TTL=1800
      # Show Ollama models as free ($0) since they run locally
      - OLLAMA_FREE=true
      # Debug mode
      - DEBUG=false
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
